[
{
	"uri": "/7646/python/",
	"title": "Python",
	"tags": [],
	"description": "",
	"content": " Python: Numpy \u0026amp; Pandas Dataframes A dataframe is a data structure in pandas that allows multiple datasets to be mapped to the same indices. For example, a data frame that maps dates to closing prices could be:\n    SPY AAPL GOOG GLD     2000-01-09 101.01 50.89 NaN NaN   2000-01-10 100.05 50.91 NaN NaN   \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip; \u0026hellip;   2015-12-31 200.89 600.25 559.50 112.37    The indices in this dataframe are the dates on the left, and the closing prices for that date are stored in each column. The ”NaN”s appear because GOOG and GLD were not publicly traded during those periods.\nReading CSVs into Dataframes To begin using the dataframes, you need data first. Historical stock data from Yahoo is provided in the form of a CSV file, which can be easily read into a dataframe using pandas’s function read csv().\nimport pandas as pd def test_run(): df = pd.read_csv(\u0026quot;data/AAPL.csv\u0026quot;) print df if __name__ == \u0026quot;__main__\u0026quot;: test_run()  This example reads in a CSV corresponding to the historic data for AAPL (Apple, Inc) into the variable df. df is a DataFrame object, which means any DataFrame methods may be used on it.\nAn example of a method that can be used is max(), which returns the maximum value in the range.\nimport pandas as pd def get_max_close(symbol): df = pd.read_csv(\u0026quot;data/{}.csv\u0026quot;.format(symbol)) return df ['Close'].max() def test_run(): for symbol in ['AAPL','IBM'] print \u0026quot;Max close \u0026quot; print symbol, get_max_close(symbol) if __name__ == \u0026quot;__main__\u0026quot;: test_run()  Plotting Matplotlib can be used to plot the data in the dataframes, as pandas can conveniently tap into the matplotlib API. Plotting data in a dataframe is as simple as calling plot() on one of the series in the frame.\nExample: Plotting the Adjusted Closea price of AAPL\nimport pandas as pd import matplotlib.pyplot as plt def test_run(): df = pd.read_csv('data/AAPL.csv') print df['Adj Close'] df[['Adj Close', 'Close']].plot() plt.title('Comparison') plt.show() if __name__ == '__main__': test_run()     index AdjClose     0 669.79   1 660.59   2 662.74   3 680.44   4 676.27   \u0026hellip; \u0026hellip;   3173 24.60   3174 24.96    Issues There are some issues with the data that need to be solved to effectively use it in the way we want.\n Trading days: The NYSE only trades for a certain number of days per year, which means that indexing by dates will return some results when the exchanges were not open. This poses problems for trying to pull out certain date ranges from the dataframe. Multiple stocks: One of the dataframe’s powers is to be able to contain multiple ranges, which means that we need to be able to retrieve multiple datasets and store them into the dataframe. Date order: The data in the Yahoo CSV are in reverse chronological order (most recent at the top), so any analysis on the dataframe will be going backwards in time, which is not ideal.  Solution to the issues To solve the trading days problem, we’ll use an Exchange-Traded Fund (ETF) called SPY (S\u0026amp;P 500) to serve as a basis for what days the stock market is open. The only days that exist in the dataset for this ETF are the days the stock market traded, so if we use this as a reference and use joining on the dataframes, we can recover data on only the days which had trading.\nExample: Using joins to get only traded days\nstart_date = '2010-01-22' end_date = '2010-01-26' dates = pd.date_range(start_date, end_date) df1 = pd.DataFrame(index=dates) # build empty dataframe  If we were to print out df1, the output would be:\nEmpty DataFrame Columns : [] Index : [2010-01-22 00:00:00, 2010-01-23 00:00:00, 2010-01-25 00:00:00, 2010-01-26 00:00:00]  This empty dataframe will be the basis for the data we want to retrieve. The next step is to join this dataframe with a dataframe with the data for SPY. This will keep only indices of the SPY dataframe that also exist in the empty one.\nExample: Reading in the new dataframe and joining them\ndfSPY = pd.read_csv(\u0026quot;data/SPY.csv\u0026quot;, index_col=\u0026quot;Date\u0026quot;, parse_dates=True, usecols=[ 'Date','Adj Close'], na_values =['nan']) df1 = df1.join(dfSPY)  The output would now be:\n Adj Close 2010-01-22 104.34 2010-01-23 NaN 2010-01-24 NaN 2010-01-25 104.87 2010-01-26 104.43  To get rid of the ”NaN”s, you can call dropna() on the newly joined dataframe, but there is a better way of joining them such that the ”NaN”s don’t appear in the first place. The join type is called an inner join, which joins at the intersection of the two dataframes. This way, only the dates which are in both will be kept as indices. Everything else will be thrown away.\nExample: The inner join\ndf1 = df1.join(dfSPY, how='inner')  Multiple stocks Reading in multiple stocks is as easy as just adding a for loop:\nExample: Reading in multiple stocks into a single dataframe\ndfSPY = dfSPY.rename(columns={'Adj Close': 'SPY'}) df1 = df1.join(dfSPY, how='inner') symbols = ['GOOG', 'IBM', 'GLD'] for symbol in symbols: df_tmp = pd.read_csv(\u0026quot;data/{}.csv\u0026quot;.format(symbol), index_col=\u0026quot;Date\u0026quot;, parse_dates=True, usecols=['Date', 'Adj Close'], na_values=['nan']) # rename to prevent name clash (multiple columns with same name) df_tmp = df_tmp . rename(columns={'Adj Close': symbol}) df1 = df1.join(df_tmp, how='inner')  Here’s an example of reading and plotting multiple stocks’ closing price on one plot\nExample: Reading and plotting multiple stocks\nimport os import pandas as pd import matplotlib.pyplot as plt def plot_selected(df, columns, start_ind, end_ind): print df.ix[start_ind: end_ind, columns] plot_data(df.ix[start_ind:end_ind, columns]) def symbol_to_path(symbol, base_dir=\u0026quot;data\u0026quot;): return os.path.join(base_dir, \u0026quot;{}. csv\u0026quot;. format(str(symbol))) def get_data(symbols, dates): df = pd.DataFrame(index=dates) if 'SPY' not in symbols: symbols.insert(0, 'SPY') for symbol in symbols: tmp = pd.read_csv(symbol_to_path(symbol), index_col=\u0026quot;Date\u0026quot;, parse_dates=True, usecols=['Date', 'Close'], na_values=['nan']) tmp = tmp.rename(columns={'Close': symbol}) df = df.join(tmp) if symbol == 'SPY': df = df.dropna(subset=['SPY']) return df def plot_data(df, title=\u0026quot; Stock prices\u0026quot;): ax = df.plot(title=title, fontsize=12) ax.set_xlabel(\u0026quot;Date\u0026quot;) ax.set_ylabel(\u0026quot;Closing price\u0026quot;) plt.show() def test_run(): dates = pd.date_range('2010-01-01', '2010-12-31') symbols = ['IBM ', 'GLD '] df = get_data(symbols, dates) plot_selected(df, ['SPY', 'IBM '], '2010-03-01', '2010-04-01') if __name__ == '__main__': test_run()  Normalizing Sometimes when plotting, the values of a stock will be significantly different from the other stocks such that it becomes difficult to tell some of them apart. Normalizing the data allows all of them to start at the same point and then show divergences from the initial point, making it easier to compare them at the same time.\nNormalizing the dataframe is as simple as dividing the entire dataframe by its first row\nExample: Normalizing a dataframe\ndef normalize_data(df): df = df / df.ix[0 ,:] return df  NumPy The actual data in the dataframe is actually an ndarray in NumPy (A multidimensional homogeneous array). That means we can do operations on the data using NumPy. For example, if you have a dataframe df1, the ndarray would be extracted by doing\nnd1 = df1.values  Accessing a cell in the array is as simple as:\nval = nd1[row, col]  You can also access subarrays by indexing with the colon:\nsub = nd1[0:3, 1:3]  would capture the rectangular subarray from the first to the third rows and the second to third columns.\nIndexing Note that the second part of the index is 1 past the actual index that will be the last, so 0:3 only pulls out 0, 1, and 2. Like in MATLAB, you can pull out everything using just the colon. For example:\nsub = nd1[3 ,:]  would retrieve all columns of row 3.\nNegative indexing To get the last index, you can use negative numbers (the last index would be -1, second to last -2, etc.)\nsub = nd1[-1, 1:3]  would get columns 1,2 of the last row\nBoolean indexing/masking Suppose we want to get the values in an array, a, which are all less than the mean. NumPy’s masking feature makes it really intuitive, as all you need to do is:\nlessThanMean = a[a \u0026lt; a.mean()]  The array a \u0026lt; a.mean() would be a boolean array, which might look like\n[[ True, True, False, False]]  Assignment Assigning values in an array is easy using the NumPy notation. For example, say we wanted to replace the values in the first 2x2 square of nd1 with the 2x2 square in nd2 with columns 2 and 3, and rows 3, and 4. The operation would be:\nnd1[0:2, 0:2] = nd2[-2:, 2:4]  Creating an array Creating a numpy array is as easy as passing in a normal python list into the array method:\nimport numpy as np print np.array([1, 2, 3])  Creating a 2D m x n array is as simple as passing in a m-long list of n-tuples.\nprint np.array([(1, 2, 3), (4, 5, 6)])  would output\n[[1 ,2 ,3] [4 ,5 ,6]]  More initializers You can also create arrays with certain initial values.\nnp.empty((5, 3, 2))  initializes an ”empty” 5x3x2 dimensional array. The values in the array are actually whatever was in the memory locations of the array pointers, so the output could look like garbage.\nnp.ones((5, 4), dtype=np.int)  creates a 5x4 array, where the value in each cell is the integer 1.\nnp.random.random((5, 4))  creates a 5x4 array with random numbers from a uniform distribution in [0.0,1.0). An example result could be:\n[[ 0.82897637 0.36449978 0.91209931 0.96307279] [ 0.63777312 0.24482194 0.5817991 0.18043012] [ 0.85871221 0.98874123 0.68491831 0.53831711] [ 0.52908238 0.81083147 0.97440602 0.81032768] [ 0.98566222 0.38902445 0.16922005 0.0873198 ]]  Other methods or fields, such as sum() or size() can be looked up in online documentation.\n"
},
{
	"uri": "/42/",
	"title": "42",
	"tags": [],
	"description": "",
	"content": " About Georgia Tech\u0026rsquo;s online Master of Science in Computer Science (OMS CS) comprises a curriculum of courses taught by the world-class faculty in the Georgia Tech College of Computing.\nGetting Started TODO: Resources/guidance for new students\u0026hellip;\nCommunities  Slack Reddit Facebook  Resources:  OMSCS FAQ: here and here Course Reviews Awesome-OMSCS Repo  "
},
{
	"uri": "/7646/statistical-analysis-of-time-series-data/",
	"title": "Statistical Analysis of Time Series Data",
	"tags": [],
	"description": "",
	"content": " Statistical Analysis of Time Series Data Pandas makes it simple to perform statistical analysis on dataframes, which is extremely important in determining different indicators and acting as inputs to the learning algorithms.\nGlobal statistics For example, if you had a dataframe df1 which had the closing prices for various stocks over a given time period, you can retrieve an ndarray with the mean of the columns by just calling df1.mean().\nFigure 2.1: Example output array for mean() (called on closing prices for January 2010 through December 2012)\nIn addition to mean, there around 32 other global statistics that are available in pandas.\nRolling statistics Instead of doing analysis on the entire dataset, you might want to do a rolling analysis, which only looks at certain snapshots of the data to sample. For example, you could have a 20-day moving mean, which you would calculate day-by-day by averaging the last 20 days’ data. In later sections, this moving average will be explained in more detail, but some critical points of interest are when the moving average crosses the data.\nBollinger bands Some analysts believe that significant deviations from the moving mean will result in movement back towards the mean. If the price dips far below the mean, then it might be a buy signal, whereas if it goes too high, it could indicate a time to sell. Bollinger bands are a way of measuring this deviation.\nBollinger observed that if you look at the volatility of the stock, and if it’s too large, then you discard the movements above and below the mean, but if it’s not, then it might be worth paying attention to.\nWhat he did was place two new moving means, one $2\\sigma$ above, and another $2\\sigma$ below the moving average. If you look at deviations near to $2\\sigma$, then they’re worth paying attention to. If the price drops below $2\\sigma$, and then rises back up through it, then it could be a buy signal. (the price is moving back towards the average).\nConversely, if the price rises above $2\\sigma$, then falls back down, it could be a sell signal.\nComputing rolling statistics in pandas Pandas provides some methods to easily calculate rolling mean (rolling mean()) and rolling standard deviation (rolling_std()).\nExample: Calculating a 20-day rolling mean\nrm_SPY = pd.rolling_mean(df['SPY'], window=20)  The Bollinger bands are calculated as follows:\ndef get_bollinger_bands(rm, rstd): return rm + 2*rstd, rm - 2*rstd  Daily returns Daily returns are how much a stock’s price went up or down on a given day. They are an extremely important statistic as they can be a good comparison between different stocks.\n$dailyReturn[t] = \\dfrac{price[t] - price[t - 1]}{price[t - 1]} = \\dfrac{price[t]}{price[t - 1]} - 1$  daily_ret = (df / df.shift(1).values) - 1 daily_ret.ix[0,:] = 0  Cumulative Returns Cumulative return is calculated by finding the gain from the beginning of the range to the current time, i.e.\n$CumlativeReturn[t] = \\dfrac{price[t]}{price[0]} - 1$  For example, if the price at the beginning was \\$125, and the current price is \\$142, then the gain/cumulative return is $\\dfrac{142}{125} - 1 = .136 = 13.6\\%$\nCumulative returns are essentially the original dataset normalized.\nIncomplete data People assume that financial data is extremely well-documented and that perfect data is recorded minute by minute. They also believe that there are no gaps or missing data points. However, for any particular stock, it might have different prices on different stock exchanges! It’s difficult to know who’s right all the time. Also, not all stocks trade every day (they might suddenly start trading or stop trading).\nYou might think you can just interpolate the data between breaks, but that’d cause statistical errors and a side-effect of ”looking into the future” when doing analysis on that subset of data. The better way of doing it to minimize error is to fill forward and backwards.\nFilling To fix the ”NaN”/empty data, you can use filling to maintain the last known value until known data is reached. For example, if you had a stock that didn’t have data until 2001 and then stopped having data in 2006 but then started having data again in 2012, you could fill forward from 2006-2012 and then fill backwards from 2001 back to whenever you want your data to start.\nExample: Filling in missing data using fillna()\ndf = get_data(symbols, dates) df.fillna(method=\u0026quot;ffill\u0026quot;, inplace=True) df.fillna(method=\u0026quot;bfill\u0026quot;, inplace=True)  Histograms and scatter plots It’s difficult to draw conclusions directly from daily returns plots, so histograms make it easier to see what’s going on. A histogram allows you to see how many occurrences of each return happens relative to other returns. This histogram typically follows a Gaussian over large periods of time.\nHistograms From the histogram we can determine a few key statistics: mean, standard deviation, and kurtosis. Kurtosis is a measure of how close the curve is to a Gaussian. In stock data, there are usually more occurrences at high deviations (causing sort of ”fat tails”), which would be reflected as a positive kurtosis. Skinny tails would mean a negative kurtosis.\nExample: Getting a histogram The histogram above was generated by just calling hist() on the daily returns dataframe as such:\ndaily_returns.hist(bins=20)  The bins parameter is essentially the resolution of the histogram. The domain is divided into 20 bins and anything within those bins counts for that bin’s count in the histogram. Other statistics like mean and standard deviation are easily calculated:\nmean = daily_returns['SPY'].mean() print \u0026quot; mean =\u0026quot;, mean std = daily_returns['SPY'].std() print \u0026quot;std deviation =\u0026quot;, std  Which outputs:\nmean = 0.000509326569142 std deviation = 0.0130565407719  We can now plot the mean and standard deviations on the plot to make analysis easier:\nplt.axvline(mean, color='w', linestyle='dashed', linewidth=2) plt.axvline(mean+std, color='r', linestyle='dashed', linewidth=2) plt.axvline(mean-std, color='r', linestyle='dashed', linewidth=2)  Showing this:\nprint daily_returns.kurtosis() \u0026gt;\u0026gt;\u0026gt; SPY 3.376644  which means that the data has fat tails since it’s positive.\nThe utility of these histograms comes when plotting them together. It’s easy to compare multiple stocks in terms of their returns and volatility. If stock A’s curve is skewed more positive and is thinner than stock B, then it has a low volatility with higher returns vs stock B.\nBy looking at this chart, you can see that SPY and XOM are about the same in volatility\n$\\sigma_{SPY} = 0.013057$, $\\sigma_{XOM} = 0.013647$. However, SPY would have higher returns since $R_{SPY} = 0.000509$ whereas $R_{XOM} = 0.000151$\nScatter plots Scatter plots are another way of visualizing the correlation between two stocks. Say you had a dataframe with the daily returns for SPY and XYZ. If you took just the ndarray containing the y-axis values, and then plotted SPY on the x-axis and XYZ on the y-axis, you would see a bunch of points that might have a certain trend.\nIf you take a linear regression of this data, the slope would be called the beta ($\\beta$) value. If the $\\beta$ value for SPY and XYZ is 1, it means that, on average, if SPY (the market) moves up by 1%, then XYZ also moves up by 1%.\nThe y-intercept of the line is called $\\alpha$. It describes how the stock on the y-axis performs with respect the stock on the x-axis. If the $\\alpha$ value of XYZ with respect to SPY is positive, then, on average, XYZ is returning more than the market overall.\nCorrelation: If there isn’t any correlation in the dataset, then the linear regression doesn’t tell you anything about the relationship. A common method for calculating the correlation is by finding the sample Pearson correlation coefficient, $r_{xy}$. It’s calculated by the following:\n$r_{xy} = \\dfrac{cov(X, Y)}{\\sigma_X\\sigma_Y} = \\dfrac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2 }\\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}$  where $cov$ is the covariance. In this case, $X$ would be the daily return for SPY and $Y$ would be the daily return for XYZ. If $|r X,Y| = 1$, then the two are perfectly correlated (either positively or negatively, depending on the sign of $\\rho$). If $|r| \u0026lt; 1$, then there is possible correlation, but a value closer to 1 means better correlation. If $r = 0$, there is no correlation.\nExample: Plotting scatter plots, getting $\\alpha$ and $\\beta$ values, and determining correlation\n# scatter plot for XOM vs SPY daily_ret.plot(kind='scatter', x='SPY', y='XOM', title=\u0026quot;Scatterplot\u0026quot;) beta_XOM,alpha_XOM = np.polyfit(daily_ret['SPY'],daily_ret['XOM'],1) plt.plot(daily_ret['SPY'], beta_XOM*daily_ret['SPY'] + alpha_XOM,'-',color='r') plt.show() # scatterplotforGLDvsSPY daily_ret.plot(kind='scatter', x='SPY', y='GLD', title=\u0026quot;Scatterplot\u0026quot;) beta_GLD, alpha_GLD = np.polyfit(daily_ret['SPY'], daily_ret['GLD'], 1) plt.plot(daily_ret['SPY'], beta_GLD*daily_ret['SPY'] + alpha_GLD, '-', color='r') plt.show() print \u0026quot;BetaXOM: \u0026quot;, beta_XOM print \u0026quot;AlphaXOM: \u0026quot;, alpha_XOM print \u0026quot;BetaGLD: \u0026quot;, beta_GLD print \u0026quot;AlphaGLD: \u0026quot;, alpha_GLD # calculate correlation using pearson method print \u0026quot;Correlationmatrix:\\n\u0026quot;, daily_ret.corr(method='pearson')  Which results in:\nBeta XOM: 0.85753872112 Alpha XOM: -0.000285580653638 Beta GLD: 0.0663816850634 Alpha GLD: 0.000660583984316 Correlation matrix: SPY XOM GLD SPY 1.000000 0.820423 0.074771 XOM 0.820423 1.000000 0.079401 GLD 0.074771 0.079401 1.000000  Looking at the $\\beta$ values, you can see that XOM is more responsive to market changes, while GLD is relatively unresponsive. However, GLD tends to perform better than the market on average, since its $\\alpha$ is positive.\nBut these values are meaningless without seeing what their correlations are. Looking at the correlation matrix, XOM is pretty well correlated with SPY, whereas GLD has a very low correlation, so changes GLD aren’t really correlated with changes in the market.\nLooking at the plots, it’s easy to see that the points for XOM are more correlated and match the line better than do those of GLD.\nSharpe ratio and other portfolio statistics The portfolio is the collection of all stocks currently owned by a person. It’s important to know various statistics associated with the portfolio to make informed decisions on what to sell/buy.\nSuppose you begin with a portfolio p consisting of the following parameters:\nstart_val = 1000000 start_date = '2009-01-01' end_date = '2011-12-31' symbols = ['SPY','XOM','GOOG','GLD'] allocs = [0.4,0.4,0.1,0.1] # @ beginning , 40% to SPY , 40% to XOM, etc  Now suppose we want to find the value of this portfolio day-by-day. If we normalize the portfolio dataframe, we essentially have a dataframe containing cumulative returns for each index. If we multiply this by allocs, we get returns scaled by each percentage of the total portfolio. Then, multiply by start val to get each stock’s total value. Finally, take the sum of this penultimate dataframe to get a single-column dataframe with the total portfolio value at each point in time. In Python,\n# get cumulative returns df = get_data(symbols, pd.date_range(start_date,end_date)) df = normalize(df) # get changes for each stock by their percentages of the starting value alloced = df * allocs # get dollar value of changes vals = alloced * start_val # sum to get total value portfolio_value = vals.sum(axis=1)  We may now compute various statistics on the portfolio’s value.\n Daily returns: Obviously, daily returns of the entire portfolio would be an important statistic, as they indicate how the portfolio changes over time. For some statistics, we need to get rid of the 0 at the beginning of the daily return or else it’ll throw off the values.  daily_rets = daily_rets[1:]   Cumulative returns: The total cumulative return of the portfolio is another interesting statistic, as you can see if the overall gain was positive or negative.  cum_ret = (port_val[-1]/port_val.ix[0,:]) - 1   Avg. and Std. Deviation: These two are the main statistics that get thrown off by the 0 at the beginning. If it were there, the mean would be closer to 0, even though technically 0 isn’t actually one of the returns.  avg_daily_ret = daily_rets.mean() std_daily_ret = daily_rets.std()  Sharpe Ratio The Sharpe Ratio is a metric that adjusts return for risk. It enables a quantitative way to compare two stocks in terms of their returns and volatility. The Sharpe Ratio is calculated based on the assumption that, Ceteris paribus,\n Lower risk is better Higher return is better  Being an economic indicator, it also takes into account the opportunity cost/return of putting the money in a risk-free asset such as a bank account with interest. A sort of risk-adjusted return may be calculated as follows:\n$R_{adj} = \\dfrac{R_p-R_f}{\\sigma_p}$  where $R_p$ is the portfolio return, $R_f$ is the risk-free rate of return, and $\\sigma_p$ is the volatility of the portfolio return.\nThis ratio is a sort of basis for how the Sharpe Ratio is calculated. The Sharpe Ratio is as follows:\n$S = \\dfrac{E[R_p-R_f]}{std(R_p - R_f)}$  Since we’re looking at past data, the expected value is actually the mean of the dataset, so this becomes:\n$S = \\dfrac{\\overline{(R_p - R_f)}}{std(R_p - R_f)}$  One question is where $R_f$ comes from. There are three main ways of getting the data for the risk-free rate:\n The London Inter-Bank Offer Rate (LIBOR) The interest rate on the 3-month Treasury bill 0% (what people have been using recently\u0026hellip;)  LIBOR changes each day, and the Treasury bill changes slightly each day, but interest in bank accounts are typically paid in 6-month or yearly intervals. Using this simple trick, you can convert the annual/biannual amount to a daily amount:\nSuppose the yearly interest rate is $I$. If we start at the beginning of the year with a value $P$, the new value after interest is paid will be $P\u0026rsquo;$. To find the equivalent daily interest value, $I_{eq}$,\n$P\u0026#39; = P(1 \u0026#43; I_{eq})^{252}$  $P(1 \u0026#43; I) = P(1 \u0026#43; I_{eq})^{252}$  $1 \u0026#43; I = (1 \u0026#43; I_{eq})^{252}$  $(1 \u0026#43; I_{eq}) = \\sqrt[252]{1\u0026#43;I}$  $I_{eq} = \\sqrt[252]{1\u0026#43;I} - 1$ \nTherefore, $R_f$, the daily risk-free rate, is just $\\sqrt[252]{1 + I} - 1$. The reason it’s 252 instead of 365 is because there are only 252 trading days in a year.\nSince we’re treating $R_f$ as constant, the standard deviation in the denominator just becomes $std(R_p)$, so the final equation for the Sharpe Ratio becomes:\n$S = \\dfrac{\\overline{(R_p - R_f)}}{\\sigma_{R_p}}$  Sampling rate The Sharpe Ratio can vary widely depending on the sampling frequency. Since $SR$ is an annual measure, any calculations that are done with samples more frequent than yearly need to be scaled to get the annual ratio. To adjust the calculated Sharpe Ratio to be ”annualized”, you just multiply by a factor of $\\sqrt{\\textrm{#samples per year}}$. So if you sample daily, the Sharpe Ratio would become:\n$S = \\dfrac{\\overline{(R_p - R_f)}}{\\sigma_{R_p}} \\sqrt{252}$  Example: Given 60 days of data with the following statistics:\n $R_p = 10bps$ $R_f = 2bps$ $\\sigma R_p = 10bps$,  what is the Sharpe Ratio? One bps is one hundredth of a percent.\nOptimizers An optimizer can: - Find minimum/maximum values of functions - Build parameterized models based on data - Refine allocations to stocks in portfolios For example, say you have the function $f(x) = (x - 1.5)^2 + .5$, and you want to find the minimum. It’s trivial to use calculus and find the minimum analytically, but you can’t always do so if you don’t have an analytical model of the data. Let’s put this in Python:\nimport pandas as pd import numpy as np import matplotlib.pyplot as plt import scipy . optimize as spo def f(x): y = (x - 1.5)**2 + .5 print \u0026quot;x = {}, y = {}\u0026quot;.format(x, y) return y def test_run(): guess = 2.0 min_result = spo.minimize(f, guess, method='SLSQP', options={'disp': True}) print \u0026quot; minima found at:\u0026quot; print \u0026quot;x = {}, y = {}\u0026quot;.format(min_result.x, min_result.fun) if __name__ == \u0026quot; __main__ \u0026quot;: test_run()  outputs:\nx = [2.], y = [0.75] x = [2.], y = [0.75] x = [2.00000001], y = [0.75000001] x = [0.99999999], y = [0.75000001] x = [1.5], y = [0.5] x = [1.5], y = [0.5] x = [1.50000001], y = [0.5] Optimization terminated successfully. (Exit mode 0) Current function value: [0.5] Iterations: 2 Function evaluations: 7 Gradient evaluations: 2 minima found at: x = [1.5], y = [0.5]  Pitfalls Optimizers aren’t perfect, and since the method used above uses the gradient of the current point to move to the next point, it can be tripped up by various abnormalities in the function it’s trying to minimize, such as:\n Flat ranges: If a portion of the graph is flat (the slope is close to or is 0), then the solver will either take a lot of iterations to solve for the minimum or it might not ever be able to move to a new point, unless it can find a way out. Discontinuities: If there are discontinuities, the gradient might not be defined well enough for the solver to continue. Multiple minima: Say you have a function $f(x) = x^4 − 2x^2 + x^2$. This function has 2 minima at $(0, 0)$ and $(1, 0)$. If the solver starts at $x = 1.5$, it’ll find the minimum at $(1, 0)$, but it won’t ever reach the other minimum. Conversely, if the solver starts at $x = −1.5$, it’ll find the minimum at $(0, 0)$. Therefore, it’s easy to get trapped in a local minimum that may not be the actual global minimum.  Convex problems A real-valued function $f(x)$ defined on an interval is called convex if the line segment between any two points on the graph of $f(x)$ on that interval lies above the graph. Otherwise, it’s called non-convex.\nLeft: a convex function. Right: a non-convex function. It is much easier to find the bottom of the surface in the convex function than the non-convex surface. (Source: Reza Zadeh)\nBuilding a parameterized model If you have a set of data points representing rainfall and humidity that were gathered, you might want to find a function that best fits those points. Say you wanted to fit a line $f(x) = mx + b$ to the points. In this case, you can use linear algebra and find the leastsquares solution, but you can also use an optimizer to find the best parameters $m$ and $b$. What does ”best” mean? Well, we can devise a measure for the error for each point:\n$e_i = (y_i - f(x_i))^2 = (y_i - (mx_i \u0026#43; b))^2$  which is just the difference between the actual value and our model’s predicted value. The reason it’s squared is to ensure that negative errors don’t reduce the total error when we sum up every $e_i$.\n$E = \\sum_{i=1}^{n} (y_i - (mx_i \u0026#43; b))^2$  Now that we have what we want to minimize, $E$, we can use a minimizer to find the best $m$ and $b$. To make the parameters nicer to work with in Python (and allow generalization to higher degrees of polynomials), we’ll rename $m$ and $b$ to $C_0$ and $C_1$. Now, $f(x) = C_0x+C_1$.\nFor example in python:\nimport pandas as pd import numpy as np import matplotlib.pyplot as plt import scipy . optimize as spo # line is a tuple (C0 , C1) def error(line, data): return np.sum((data[:, 1]-(line[0]*data[:, 0]+line[1]))**2) def fit_line(data, error_func): # initial guess for parameters l = np.float32([0, np.mean(data[:, 1])]) return spo.minimize(error_func, l, args=(data,), method='SLSQP', options={'disp': True}).x def test_run(): original = np . float32([4, 2]) print \u0026quot; original line : C0 = {} , C1 = {}\u0026quot;. format(original[0], original[1]) Xoriginal = np . linspace(0, 10, 40) Yoriginal = original[0] * Xoriginal + original[1] plt.plot(Xoriginal, Yoriginal, 'b--', linewidth=2.0, label=\u0026quot;Originalline\u0026quot;) # add some random noise to the data noise_sigma = 4.0 noise = np.random.normal(0, noise_sigma, Yoriginal.shape) data = np.asarray([Xoriginal, Yoriginal+noise]).T plt.plot(data[:, 0], data[:, 1], 'go', label=\u0026quot;Data points\u0026quot;) l_fit = fit_line(data, error) print \u0026quot; Fitted line : C0 = {}, C1 = {}\u0026quot;.format(l_fit[0], l_fit[1]) plt.plot(data[:, 0], l_fit[0]*data[:, 0] + l_fit[1], 'r- -', linewidth=2.0, label=\u0026quot; Fitted line \u0026quot;) plt.legend(loc='upperright') plt.show() if __name__ == '__main__': test_run()  Portfolio Optimization Now that wee have the tools to optimize a function, we can use it to optimize our portfolio! We can choose to optimize/minimize/maximize various measures, such as daily returns, cumulative returns, or Sharpe Ratio based on the percent allocation of all of the stocks in the portfolio.\nFraming the problem First we need three things:\n a function, $f(x)$, to minimize an initial guess for $x$ the optimizer  In our case, $x$ is actually the set of allocations for the stocks. Also, since we want to maximize Sharpe Ratio, we need to multiply $f(x)$ by $-1$ to call the minimizer.\n MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\\\(','\\\\)']], displayMath: [['$$','$$'], ['\\[','\\]']], processEscapes: true, processEnvironments: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], TeX: { equationNumbers: { autoNumber: \"AMS\" }, extensions: [\"AMSmath.js\", \"AMSsymbols.js\"] } } });  MathJax.Hub.Queue(function() { // Fix  tags after MathJax finishes running. This is a // hack to overcome a shortcoming of Markdown. Discussion at // https://github.com/mojombo/jekyll/issues/199 var all = MathJax.Hub.getAllJax(), i; for(i = 0; i "
},
{
	"uri": "/7646/",
	"title": "7646",
	"tags": [],
	"description": "",
	"content": " About: This course is part of the OMSCS ML specialization and is taught by the Quantitative Software Research Group at Georgia Tech. It covers pythons and introductory numerical computing, computational investing, and applied machine learning.\nResources:  Course website Calendar Software Setup Q\u0026amp;A Study Guide    Credit: much of this section comes from Ryan Babaie \u0026amp; Neil Hardy\u0026#39;s guide. Download it here:   ml4t_guide.pdf  (1401 ko)    "
},
{
	"uri": "/7646/essential-economics/",
	"title": "Essential Economics",
	"tags": [],
	"description": "",
	"content": " Essential Economics This chapter discusses terminology, stock market dynamics, and important indicators in economics. This will allow us to more accurately judge the value of an economic decision and make predictions on the market.\nFunds We’ll discuss three different types of funds: Exchange-Traded Fund (ETF), mutual funds, and hedge funds. Different types of funds are governed under different rules. ETFs are similar to stocks in that they are bought and sold at will like stocks- very liquid. However, ETFs typically represent baskets of stocks, and it is known to the trader what the fund represents. Mutual funds can only be bought and sold at the end of the day, and the holdings within a mutual fund are only disclosed every quarter. The least transparent holdings are that of a hedge fund. Before investors can buy shares in the fund, they must sign a long term agreement and holdings are rarely disclosed.\nAbout Funds For stocks and ETFs, having a large ”cap” means that the total value of stocks (number of stocks × price of a stock) in a company is worth many billions of dollars. Moreover, the price of a stock doesn’t reflect the value of a company, but the price at which they are selling shares. ETFs, like stocks, can easily be traded through individuals alone, whereas shares in mutual funds require a broker and hedge fund shares require more of a one on one relationship. Managers of ETFs and mutual funds are compensated based on expense ratios, which denote a percentage of Assets Under Management (AUM). For an ETF, expense ratios range from 0.01% to 1%, and in mutual funds from 0.5% to 3%. Hedge funds follow a ”two and twenty” policy, where managers get 2% of the AUM and 20% of the profits.\nThe type of a fund can be more easily recognized by how it’s named. For example, an ETF has a ticker, or stock symbol, with three or four letters, like AAPL. A mutual fund has five letters, like VTINX, and a hedge fund doesn’t have a ticker because shares are much less liquid. How much money is managed by a fund is known as the AUM, and shares represent percentages of the AUM.\nIt’s fairly clear to see that hedge funds are very different from ETFs and mutual funds. Hedge funds typically have no more than 100 investors, whereas ETFs and mutual funds have thousands. Those that invest in hedge funds are typically very wealthy individuals, institutions, and funds of funds. Funds of funds typically take large sums of money from potentially many places and invest in several hedge funds. This is a bridge for smaller investors to participate in hedge fund. The goal of a hedge fund typically falls along the lines of two ideals. The hedge fund may be out to beat a bench mark which is to say that the hedge fund aims to outperform an index of stocks. A hedge fund could also aim for absolute return, which translates to net positive profit no matter what, but usually takes more time and has fewer returns as a trade off for stability. We’ll be focusing on hedge funds because they are the most computationally demanding.\nFund Metrics and Operations Measuring the performance of a fund is vital for making financial decisions in the market, so here we’ll discuss a few. Overall success can be measured by cumulative return, which is the percentage of an original value made in a given time: $\\dfrac{\\textrm{end - start}}{start}$. However, this means little if the portfolio is rapidly and wildly fluctuating. Hence it’s also useful to measure the volatility of a portfolio. This is simply measured by the standard deviation of daily returns; it’s best to have low volatility. Another important measure is the return on risks. This is done by calculating the Sharpe Ratio (SR), also called risk-adjusted reward.\n$SR = \\sqrt{252} \\dfrac{mean(\\textrm{daily returns} - \\textrm{risk free rate})} {volatility}$  The factor of $\\sqrt{252}$ comes from the number of trading days in a year. These factors can give us an idea of how well a portfolio is performing.\nAs previously mentioned, hedge funds are very computationally intensive environments. Let’s delve into the details of how a typical hedge fund works. Central to the operation of a hedge fund is its trading algorithms. Normally, a target portfolio is decided upon, then historical stock data and the target portfolio are fed to the trading algorithms to produce orders. The orders are sent to the market to alter the live portfolio, which is again fed back into trading algorithms.\nTrading algorithms work to place certain orders at the proper time. For example, an order for everything in the target portfolio shouldn’t be placed all at once because the price of the stock will go up and more money is spent than if strategic ordering were implemented. Additionally, there is another set of computational structures for determining the target portfolio.\nHistorical data, current portfolio, and prediction algorithms are fed into an optimization program to produce a target portfolio. The majority of machine learning comes into play when determining the market forecast.\nMarket Mechanics Ordering The live portfolio is altered by giving orders to a broker in the stock market, so it serves to know what exactly is in an order. The broker needs to know whether to buy or sell and of which stock(s) by their market symbols. The order must also contain the number of shares and the type of order. Stock exchanges only consider limit orders and market orders, but note that orders can be increasingly complex based on instructions given to a broker. A market order is an order at the current market price, and ordering at a limit price tells the broker to only buy or sell at a certain price; for example, some may not want to buy beyond some value or sell below some price. Of course, a limit order must also include the desired price.\nAfter the broker sends the order to the stock exchange, it is made public in the style of an ”order book”. Others can see the stocks and collective bids that have been made on them, but not who has placed the orders. The order book contains a list for each stock of the orders within it including whether the order asks for others to buy or bids on the stock. Both types include a price at which orders are allowed to be bought/sold at and the size of the order. Orders of the same type and price are lumped together. Market orders always sell at the highest bid and buy at the lowest asking price.\nThe example order book suggests that the price of the stock will decrease because there is much more selling pressure- more are selling than buying.\nDynamics of Exchange There are many stock exchanges, and each has its own order book. When an order is placed, say by an individual, the order is sent to the broker and the broker chooses between the stock exchanges to execute that order. The broker takes information from all the stock exchanges and makes a transaction based on which one has the stock with the best price. Fees are associated with making transactions in stock exchanges and with using a broker. A broker typically has many clients; the broker can observe clients who want to buy and sell at the same price and circumvent stock exchanges entirely. The law ensures that this trade can only happen if both the buyer and seller get prices that are at least as good as at an exchange. Even if this transaction cuts out the stock exchange, it must still be registered with one, and it’s usually with the exchange the stock is housed.\nOrders can be handled internally or moved through what’s called a ”dark pool”. A dark pool is a place where investors can trade without the transparency of an order book outside of a stock exchange. The results of the trade, like internal trades, still need to be registered with public exchanges after they’ve occured. A dark pool can act as an intermediary between all types of investors that may want to escape the transparency of stock exchanges. Brokers like this because they don’t have to pay fees associated with trading at a stock exchange. They also argue that it’s fair because clients are getting prices that are as good as at the market. However, hedge funds and dark pools can heavily exploit this system as it stands if they have well-placed, fast computers.\nExploiting the Market These days the market is entirely digital and computers automate transactions all across the country. As a result, orders can be processed in fractions of a second, and timing is everything. A hedge fund may pay stock exchanges enough money to house computers very close to the exchanges, which gives them a distinct advantage. For example, let’s say that someone places an order for a stock, and it’s sent to multiple markets. A hedge fund close to those markets can see that order reach one of them first and buy up that stock from the other exchanges through the high speed infrastructure they have in place. Then when that order reaches other exchanges, the hedge fund has already bought those shares and sells it back at a higher price. This is one of many strategies in High Frequency Trading (HFT) that takes place on the order of milliseconds.\nThis can also happen on an international scale. A hedge fund may have computers collocated with international markets rapidly observing and comparing order books between them. If a difference occurs in a stock between the two markets, all that needs to be done is to sell in the market with a higher price and buy in the market with a lower one. This happens very quickly, so the price of the stock is not very different at different markets. HFT strategies usually trade high volumes to turn a large profit in small price differences.\nThose that operate on HFT strategies can not only manipulate a transparent market, but also a dark one. First, let’s explain why someone would want to use a dark pool. For example, an investor who wants to sell a high volume of shares in a transparent market would want to do so in small chunks so as not to upset the price all at once and get less for the shares. However, others will see this and lower their bids knowing that a high volume is to be sold and the investor still gets less for their shares. In a dark pool, others can’t see those that want to buy or sell, so the investor may get a better price. There are many ways to exploit a dark pool, but it always stems from information leakage. Knowing the order book of a dark pool means a world of advantage. Dark pool operators or constituents may secretly participate in their own pool or leak information about it to others for a price. The private nature of a dark pool allows those who operate it to make their own rules about who can participate and how trading works. Since information is at the discretion of the operator, it’s fairly easy for those with direct access to exploit a dark pool. Those that don’t have direct access can ”game” the pool by probing it with many small volume orders. This yields some idea of the size and prices of bids, which gamers can exploit by selling when they find the bids are highest and buying when asking is lowest.\nOther Orders and Shorting Although exchanges only take market and limit orders, other orders can be made through a broker. Often a broker implements them for clients without their knowledge to benefit both themselves and the client. The most simple order above a limit order is a stop-loss order. The broker holds stock until the price drops below a certain price, then sells at market price. Similarly, a stop-gain order waits until the price climbs to a point at which the client wants to sell. Slightly more complex is the trailing stop. Here the broker sets a stop-loss criteria trailing a stock that’s increasing in price. As the price increases, so does the stop-loss criteria; when that stock starts to decrease, the stop-loss criteria is met and stocks are sold.\nWhat if someone wanted to bet that a stock will decrease and still profit? Instead of just selling high and buying low, those stocks can be borrowed and sold, so the value of those stocks is gained at a high point but the stocks are still owed. Then when the price of the stock decreases, the stock can be bought at a lower value, and the shares returned to whom they were borrowed while a profit on the difference was made. This is called shorting. As long as the price of the stock goes down, this is a good strategy; however, if the price goes up, then the difference results in a net loss.\nWorth: Company Valuation The price of a company’s stock is intended to reflect the value of the company. Ergo, if the price of a company’s stock deviates significantly from its predicted value based on the company’s predicted worth, then there’s a profitable opportunity for when it returns to reflect the company’s worth. The value of the company can be estimated several different ways. One way is to estimate its intrinsic value, which is based on the future dividends the company will give; these are annual payments to stockholders. This doesn’t really describe what the company has though. The book value of a company is founded in the company’s assets like its facilities and resources. A company’s market cap is yet another way to estimate a company’s worth, and it’s easiest to calculate. This is effectively what the stock market thinks what the company is worth and it’s the value of a stock multiplied by the total number of stocks.\nIntrinsic value may not make sense if we try to imagine the value of a company that will pay dividends consistently as long as it stands. However, the company can never be 100% reliable, so the value of its dividends amount to the value of a promise. The promise of some money in a year is worth less than the same amount given right now because of this principle. Thus, the value of a those promised dividends decreases as the time they’re promised is longer, so the total value will converge to a calculable value. Similarly, we can calculate the present value (PV) of a dollar that is promised after a certain time. It makes sense that the PV of a dollar promised right now is a dollar, but what about in a year? The PV is some fraction of its future value (FV) based interest rate (IR) and the length of time, $t$.\n$PV = \\dfrac{FV}{(1\u0026#43;IR)^t}$  In this way we have a conversion between the present value and future value of some amount of money. The interest rate is also called the discount rate and it reflects the risk involved with investment. A more stable company will have a lower discount rate because they’re more reliable. The intrinsic value, IV, of a company can be calculated knowing its discount rate and dividend payments by\n$IV = \\dfrac{FV}{IR}$  Thus, if a hypothetical company pays dividends of \\$5 a year and has a discount rate of 1%, then the value of this company is $ \\dfrac{$5}{0.01} = \\$500 $. Book value of a company is simple to calculate because it is just what the company has versus what the company owes. If a company only has a factory worth \\$1 million, a patent worth \\$500,000, and a loan of \\$200,000, then the company is worth \\$1 million − 200,000 = \\$0.8 million. The patent is considered an intangible asset and isn’t counted in calculating the book value.\nNews about companies can drastically change some of these measures. Investors reflect their opinions on the worth of a company through stocks- if they feel the company is worth less, they will sell and vice versa. Let’s say bad news about a company comes up; investors will see that as increased risk in investing in the company. The company will have to increase their IR to appease investors and the intrinsic value of the company will reduce. This would also reduce the stock price of the company, which decreases the market capitalization of the company. News can affect singular companies, sectors of business, and the market as a whole depending on the scope of the news.\nMarket strategies are based on deviations in the estimated values of a company. For example, if the intrinsic value of a company drops and the stock price is relatively high given its history, then it would probably be a good idea to short that stock because the price will almost certainly go down. The book value of a company provides somewhat of a minimum for the market cap; that is because if the market cap goes below the book value, then a predatory buyer typically buys the whole company, breaks it apart, and sells its parts for the book value to turn a profit.\nThe Capital Assets Pricing Model The Capital Assets Pricing Model (CAPM) is a model that is used to predict the return of stocks. To understand this model, a portfolio must be understood in more depth. The term portfolio has been used throughout this text, but has yet to be clearly defined; a portfolio is a set of weighted assets, namely stocks. A portfolio is a set of stocks that are weighted by their value, and all the weights add to 1. Some stocks might be shorted, so technically their portfolio value is negative and really the sum of the absolute value of their weights is mathematically written, where $ w_i$ is the weight of a stock in a portfolio\n$\\sum_{i} |w_i| = 1$  and the return of the portfolio for a given day is\n$\\sum_{i} w_i r_i$  where $r_i$ is the return for a stock in a day. As an example, lets say a portfolio is composed of two stocks, A and B, and their respective weights are 0.75 and -0.25 because stock B is shorted. Then if on a given day, stock A increases by 1% and stock B decreases by 2%, the result is a portfolio return of (0.75)(0.01) + (−0.25)(−0.02) = 1.25%.\nA similar portfolio can be made for entire markets. Although, it’s typically limited to an index which includes the largest companies in a market, like the S\u0026amp;P 500 for the US market. These companies are weighted by their market caps, so a company’s weight in the market is approximately that company’s cap, c, divided by the sum of all caps.\n$w_i = \\dfrac{c_i}{\\sum_{j} c_i}$  The CAPM predicts the return on stocks within a certain market with the simple equation\n$r_i[t] = \\beta_i r_m[t] \u0026#43; \\alpha_i[t]$  This says that the return of a stock is largely based on the return of the market as a whole, $r_m$. The degree to which a stock is affected is based on that stocks particular $\\beta$ value. Fluctuations that deviate from this are represented in the (theoretically) random variable, $\\alpha$, which (theoretically) has an expected value of zero. The $\\beta$ and $\\alpha$ values of a stock are calculated based on the historical data of daily returns. The daily returns of a stock are plotted against that of the market and the slope of the fitted line constitutes the $\\beta$ value. The y-intercept and random deviations describe the $\\alpha$ value.\nCAPM and Related Theories The nature of CAPM suggests a specific strategy when approaching the market. CAPM says that the relationship of stocks to the market is linear with an average fluctuation of zero from this relationship. This suggests that the best tactic is to simply choose a set of stocks that will perform well with a certain market environment and sit on them. Active management is a way of thinking that believes the $\\alpha$ value is not entirely random and can be predicted. This mindset promotes carefully choosing and trading stocks on a regular basis depending on predicted $\\alpha$ values. This is the dichotomy between active and passive portfolio management. If we assume that $\\alpha$ is entirely random, then the only way we can beat the market is by predicting the return on the market. However, this is not entirely true, and CAPM will be used to eliminate market risk entirely.\nCAPM gives $\\beta$ values to each stock, but there are other theories that say it’s more complicated. One of these is the Arbitrage Pricing Theory (APT), which says that there is not a contribution based on the whole market, but based on its sectors. Moreover, a stock is affected by what happens in the ten different sectors of the economy, and the CAPM equation becomes\n$r_i = \\sum_{j} \\beta_{ij}r_j[t] \u0026#43; \\alpha_i[t]$  where $j$ denotes the different sectors. This provides a more in-depth prediction of stock return.\nUsing the CAPM Now we want to use the CAPM to create a lucrative portfolio. If we say that the return on the market can never be predicted, then any component associated with market return is risk. Applying the CAPM equation to get an overall portfolio return yields\n$r_p = \\sum_{i} w-I[\\beta_ir_m(t)\u0026#43;\\alpha_i(t)] $  The only way to remove the market return component is to choose weights such that $\\sum_{i}w_i\\beta_i = 0$. At this point it may seem that there will not be an expected return for the portfolio because CAPM predicts $\\alpha$ to be random. It is here that the assumptions of CAPM are wrong. Using some information, we can predict whether a stock will perform better or worse than the market, which will yield a profit regardless of which way the market goes. This information can come from expertise, some analysis, or, in our case, machine learning.\nTechnical Analysis There are effectively two kinds of analysis: fundamental and technical. Fundamental analysis looks at the properties of a company to determine market decisions. Technical analysis looks at patterns in stock prices to make market decision; since technical analysis is clearly more useful aside from predatory buying, that’s what will be discussed.\nTechnical analysis only focuses on stock price and volume. Using these to calculate statistics gives indications on what economic decisions to make. Technical analysis is most useful on shorter time scales and when combinations of indicators point to the same decision. HFT trade at the millisecond timescale and fundamental analysis firms operate at the timescale of years; humans and computers tend to work together at a timescale in between.\nSome Good Indicators It’s useful to develop strategies based on time-series indicators, so here are a few. Momentum is a scale dependent indicator that suggests an upward or downward trend depending on slope. Moreover, an n-day momentum, $m$, for a stock with price function, $p[t]$, is calculated as\n$m = \\dfrac{p[t]-p[t-n]}{p[t-n]} = \\dfrac{p[t]}{p[t-n]} - 1$  This is simply the difference in price as a ratio to the price n days ago. Typically 5, 10, or 20 day momentum is used with values ranging from -0.5 to 0.5. Another indicator is a simple moving average (SMA); SMA is also scale dependent looking over an n-day window. The price of a stock over n days is averaged and plotted over time where points are placed at the leading end of the window. However, to get a useful value, this needs to be compared to the real time price. Like momentum, it is done as a ratio\n$SMA[n] = \\dfrac{p[t]-E(p[t-n:t])}{E(p[t-n:t])} = \\dfrac{p[t]}{E(p[t-n:t])} - 1$  Momentum and SMA together often prove to be strong indicators. For example, if there is strong positive momentum and a crossing of the price from the price being lower than the average to above- this is a good indicator the price will increase. Larger than normal deviations from the moving average are expected to return back to the average and indicate opportunities. Thus, if SMA is positive, it’s a selling opportunity, and a buying opportunity if SMA is negative.\nHow those decision are made depends on the state of the stock, or its volatility. The standard deviation of the stock’s fluctuations provides an excellent measure for when to make decisions. It depends on how certain we want to be that the price is an outlier. The farther the decision threshold is from the SMA, the more certain we are that the price is an anomaly. From basic statistics, if the decision threshold is placed two standard deviations away from the SMA, then we are 95% sure the price is an anomaly. These bands, typically at two standard deviations away from SMA, are called Bollinger bands. The way this is written mathematically is, again, a ratio, which is between the price difference and the $2\\sigma$ length where $\\sigma$ is the standard deviation.\n$BB[t] = \\dfrac{p[t] - SMA[t]}{2\\sigma}$  When making economic decisions, a Bollinger band value greater than 1 denotes a selling opportunity, and less than -1 denotes a buying opportunity. However, it’s better to trade when the price crosses the band for the second time because that signals the price moving in a profitable direction.\nWhen using these values in a machine learner, it’s important that indicators are normalized. To normalize values, follow\n$normal = \\dfrac{value-mean}{\\sigma}$  This provides a z-score by which to compare everything.\nAdjusted Prices Analysis of historical data is crucial for determining patterns and making economic decisions, but some things drastically change the price of stocks without having any effect on the real value of the stock. Dividends and stock splits are two things that do just that. The adjusted price accounts for these events and corrects the computational problems that would occur if only the price were taken into account.\nStock splits occur when the price of a stock is too high and the company decides to cut the price, but increase the volume so that the overall market cap is the same. This is a problem when dealing with data because it’s seen as a large drop in price. The adjusted price is calculated going backwards in time; moreover, the given and adjusted price are the same for a certain starting present day and adjusted going backward in time. If the price is ever split, say by 3, then at the time of the split, the price is divided by 3 so that there is no discontinuity.\nAt the time a company announces the date for payment of dividends, the price of the stock will increase by the amount of a dividend until they’re paid at which point the price rapidly decreases by that amount. This is adjusted looking back in time, and on the day a dividend is paid, the prices preceding are decreased by the proportion of the dividend payment.\nAs a note for machine learning, the data that is chosen for the learner is very important. If the stocks from today are chosen and analyzed starting from 7 years ago, then those stocks will of course do well because they’ve survived. That’s using a biased strategy, so what needs to be done is to take index stocks from 7 years ago and run with those. For adjusted price, it’s also important to note that the adjusted price will be different depending on where the starting point is chosen, and that should also be taken into account.\nEfficient Markets Hypothesis Until now, we’ve been assuming, for technical analysis, that there is information in historical data that we can exploit to determine what the market is going to do. The same goes for fundamental analysis in terms of fundamental data. However, the Efficient Markets Hypothesis says that we’re wrong on both accounts!\nHere are some assumptions of the Efficient Markets Hypothesis:\n Large number of investors: The most important assumption of EMH is that there are a large number of investors for-profit. They have incentive to find where the price of a stock is out of line with its true value. Because there are so many investors, any time new information comes out, the price is going to change accordingly. New information arrives randomly Prices adjust quickly Prices reflect all available information  The three forms of the EMH There are 3 forms of the EMH, ranging from weak to strong.\n Weak: Future prices cannot be predicted by analyzing historical prices. This leaves room for fundamental analysis, however. Semi-strong: Prices adjust rapidly to new public information Strong Prices: Prices reflect all information, public and private  Is the EMH correct? If the EMH is correct, a lot of what we’re trying to do is impossible, so we should cut our losses and go home. Luckily, there is evidence for why certain versions of the hypothesis are incorrect. The existence of hedge funds indicates that you can profit by investing in stocks other than the market portfolio.\nThe strong version is the weakest of the three, considering there are many examples of insiders using esoteric information for their own benefit. And in many cases, these people have gone to jail!\nThere is also data that shows that the semi-strong version isn’t too likely to be correct. You can see trends in 20-year annualized returns versus 10-year P/E ratio data, which means that you most likely can use fundamentals to predict future performance.\nThe Fundamental Law of Active Portfolio Management Richard Grinold was trying to find a way of relating performance, skill, and breadth. For example, you might have lots of skill to pick stocks well, but you might not have the breadth to use that skill. So he developed the following relationship:\n$performance = skill\\sqrt{breadth}$  So we need some way of measuring skill and breadth. Performance is summarized by something called the information ratio:\n$IR = IC\\sqrt{BR}$  where IC is the information coefficient, and BR is the number of trading opportunities we have.\nThe Coin-flipping Casino As a thought experiment, instead of buying and selling stocks, we’re going to flip coins, and bet on the outcome. This is analogous to buying a stock and holding it– either you earn or lose money.\nThe coin is biased (like $\\alpha$) to P(heads) = .51. The uncertainty of the outcome is like $\\beta$.\nBetting: Betting works by betting on N coins. If we win, we now have 2N coins. If we lose, we now have 0 coins, so this is an even-money bet (you either gain N coins or lose N coins.)\nThe Casino: The casino has 1000 tables, each with a biased coin, and you have 1000 tokens, so you can bet them in any way you like: 10 tokens each on 100 tables, 1 token on each table, or 1000 tokens on 1 table. Once bets have been placed, the coins are all flipped in parallel, and for each game you either lose your chips or win. So now the question is what scenario is going to net you the best outcome? Let’s take the following two bets for example:\n 1000 tokens on one table and 0 on the other 999 1 token on each of 1000 tables  Which is better? Or are they the same? In fact, the expected return of both bets are the same, but bet 2 is much less risky, as with bet 1, if you lose, you lose all of your money, but with bet 2, you might lose around half your money. In fact, the chance of losing all of your money (if you bet tails) is:\n$(.49)^{1000} \\approx 10^{-310}$  To determine which is best, we need to consider risk and reward. In this case, the reward is our expected return. If $P_w$ is the chance we would win, and $P_l$ is the chance that we would lose, and $W$ is the amount we would win, whereas $L$ is the amount we’d lose, expected return for a single bet is calculated as follows:\n$E[R] = P_wW \u0026#43; P_lL$  For the biased coin where we place all of our bets on one table, this would be:\n$E[R] = .51(\\$1000) \u0026#43; .49(−\\$1000) = \\$20$  If we placed 1 token on each table, the expected return would be:\n$E[R] = \\sum_{i=1}^{1000} .51(\\$1) \u0026#43; \\sum_{i=1}^{1000} .49(−\\$1000) = \\$20$  So, in terms of reward, neither is better or worse. So how do we choose how to allocate the tokens? It turns out that the risk makes it easy to choose.\nFirst, what’s the chance that we lose it all? For the case where all of our tokens are on one table, the chance is 49%. For the second table, it’s around $10^{-308}%, which is quite a bit smaller\u0026hellip;\nAnother way to look at the risk is by looking at the standard deviation of the bets. An example of the outcomes for situation 2 is:\n$−1, 1, 1, 1, −1, −1, 1, −1, ..., 1$  The standard deviation of which is just 1. Now, for the case where we put all of our tokens on one table, the outcomes look like this:\n$1000, 0, 0, 0, 0, ..., 0$  or\n$−1000, 0, 0, 0, 0, ..., 0$  The standard deviation (risk) in both cases is $\\sqrt{1000} \\approx 31.62$, which is much higher than the standard deviation for putting bets on each table. Now, we can create a risk-adjusted reward (Sharpe Ratio) for the single-bet case:\n$R_s = \\dfrac{\\$20}{\\$31.62} = 0.63$  For the multi-bet scenario, it’s:\n$R_m = \\dfrac{\\$20}{\\$1} = 20.0$  Clearly, the second case wins based on this ratio. Something interesting about these results is that:\n$20 = .63\\sqrt{1000}$  It turns out that this can be generalized to\n$SR_{multi} = SR_{single}\\sqrt{bets}$  Which shows that as we increase the number of bets (diversify), the Sharpe Ratio increases. This is the relationship described in the Fundamental Law of Active Portfolio Management; to increase performance, you can either increase skill or diversify (bets), although diversification only goes as the square root.\nNow, back to equation 3.1. Let’s define what information ratio means. If we consider the CAPM equation:\n$r_p[t] = \\beta_p r_m[t] \u0026#43; \\alpha_p[t]$  we can associate the first term, $\\beta_p r_m[t]$ with the market, and the second term, $\\alpha_p[t]$ with skill. Information ratio is defined as:\n$IR = \\dfrac{\\overline{\\alpha_p[t]}} {\\sigma_{\\alpha_p[t]}}$  Information ratio can be thought of as a Sharpe Ratio of excess return (due to skill). Now, the information coefficient, IC, is the correlation of forecasts to returns. IC can range from 0 (no skill) to 1 (perfect skill). BR, or breadth, is the number of trading opportunities per year. For example, if you are Warren Buffet, and hold only 120 stocks for a whole year, BR is just 120. However, if you have 120 stocks and trade them daily, $BR = 120∗365$.\nLet’s do an example: say that James Simons and Warren Buffet both have the same information ratio, and that Simons’ algorithm is 1\u0026frasl;1000 as smart as Buffet’s. Buffet only trades 120 times per year. How many trades per year must Simons execute to have the same information ratio (performance)?\n$IR_S = IC_S\\sqrt{BR_S}$  $IR_B = IC_B\\sqrt{BR_B}$  $IR_S = 1/1000IC_B$  $\\dfrac{IR_B}{IR_S} = \\dfrac{IC_S\\sqrt{BR_S}}{IC_B\\sqrt{BR_B}} = 1$  $= \\dfrac{\\dfrac{1}{1000}\\sqrt{BR_S}}{\\sqrt{BR_B}}$  $\\Rightarrow BR_S = (1000)^2 BR_B$  $= 120,000,000$ \nSo Simons must execute 120 million trades, whereas Buffet only needs to execute 120. That’s quite a difference! Indeed, skill is an extremely important factor in performance.\nPortfolio Optimization Now we wish to optimize a portfolio, and what this means is minimizing risk for a given target return. Risk is largely defined as the volatility of a stock. A portfolio is composed of some stocks that individually have their own return-risk ratios, but it is possible to weight them such that the return-risk ratio of the portfolio is higher than that of any individual stock.\nThis is done through combining correlated and anti-correlated stocks to highly reduce volatility. In the case of a highly correlated group of stocks, their combination results in a similar volatility, but if they’re combined with highly anti-correlated stocks, then with accurate weighting, fluctuations cancel out and volatility is minimal while yielding similar returns. A useful algorithm to find the best weighting is mean variance optimization (MVO). This algorithm is not explained, but we should find it. MVO and similar algorithms find the minimal risk for a given target return, and if this is plotted over all target returns, we get a curve called the efficient frontier. On a return-risk plot, a line tangent to the efficient frontier with an intercept at the origin also points to the portfolio with the minimal Sharpe ratio.\n MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\\\(','\\\\)']], displayMath: [['$$','$$'], ['\\[','\\]']], processEscapes: true, processEnvironments: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], TeX: { equationNumbers: { autoNumber: \"AMS\" }, extensions: [\"AMSmath.js\", \"AMSsymbols.js\"] } } });  MathJax.Hub.Queue(function() { // Fix  tags after MathJax finishes running. This is a // hack to overcome a shortcoming of Markdown. Discussion at // https://github.com/mojombo/jekyll/issues/199 var all = MathJax.Hub.getAllJax(), i; for(i = 0; i "
},
{
	"uri": "/6242/",
	"title": "6242",
	"tags": [],
	"description": "",
	"content": "TODO: coming soon\u0026hellip; PR\u0026rsquo;s welcome\n"
},
{
	"uri": "/7646/machine-learning-algorithms/",
	"title": "Machine Learning Algorithms",
	"tags": [],
	"description": "",
	"content": " Machine Learning Algorithms In most cases, machine learning algorithms are focused on building a model. Then, the model can be used to take inputs and give outputs based on the model. The model is a tool to predict outputs based on the inputs. In our case, we will be using models to take information about stocks and predict their future prices.\nSo we use machine learning to take historical data and generate a model. When we want to use it, we give the model observations, $\\vec{x_i}$, and it gives us predictions, $y$. Examples of good inputs (predictive factors) are:\n Price momentum Bollinger value Current price  while examples of outputs would be:\n Future price Future return  We’ll first talk about Supervised Regression Learning.\nRegression and Modeling Supervised Regression Learning means that we’ll provide (supervised learning) a bunch of example data $(x, y)_i$ and allow the model to make a numerical prediction (regression). There are two main types of regression techniques:\n Linear regression (parametric) k-nearest neighbor (kNN) (instance-based), the more popular approach Decision trees Decision forests  Assessing a Model Assessing a model is much like predicting prices as it uses indicators to judge the effectiveness of the model. The first indicator is root mean square error (RMSE), which is as follows\n$\\sqrt{\\dfrac{\\sum (ytest - ypredict)^2}{N}}$  The error that is important is that of test data, which is outside of the training data. Typically 60% of the data is used for training, and 40% is used for testing. However, sometimes there isn’t enough data to adequately evaluate a learning algorithm, in which case a method called cross validation is used. This method slices the data into chunks, typically fifths. One is chosen as test and the rest are for training, then a different chunk is chosen to be the test and another trial is run. For financial data, we don’t want to accidentally look forward in time, so we would only use roll forward cross validation. This simply demands that all the training data is before the test data.\nThe second metric for how well an algorithm is working is the correlation of the test data and predicted values. Strong correlation, close to $\\pm1$, indicates a good algorithm whereas a weak correlation, close to zero, indicates a poor algorithm. Correlation and RMSE are excellent indicators on how well an algorithm is doing, but we might also want to fine tune an algorithm; we want to answer the question ”when are we trying too hard to fit data?”. This is where overfitting comes into play. Overfitting is the point at which error for training data is decreasing while error for test data is increasing.\nTypes of Learners Ensemble Learners Ensemble learners are composed of several different learners, which could include kNN, regression, and decision tree learners in one. The output of this learner is then simply a combination of the learners’ answers, which is typically an average of the outputs.\nBagging and Boosting Boot-strap aggregating, or bagging, only uses one algorithm, but many different models. If the training data is separated into learning instances where there’s a total of $n$ instances, then each model is fed a bag of these instances. Each bag is composed of $n\u0026rsquo;$ learning instances that are randomly selected with replacement, so instances may show up more than once in the same bag. These are used to train m models and the result is the average of all the outputs. Boosting builds each subsequent bag based on the results of the last. Training data is also used to test the models, and a model’s predicted data showing significant error is weighted to more likely be in the next bag for the next model. The process is continued for the desired number of models, and the results are averaged. Although this could be advantageous in predicting outliers, it’s also more susceptible to overfitting.\nReinforcement Learning As seen in figure 4.1, reinforcement learning describes the interaction of a robot with its environment. The robot performs an action, which has an effect on the environment and changes its state. The robot observes the change in state and its associated reward and makes decisions to maximize that reward.\nReinforcement learning also describes the problem that is how to go about maximizing the reward. In the stock market, the reward is return on trades, and we want to find out how to maximize returns. This problem is complicated by time constraints. The value of future gains diminishes with time, so it’s unreasonable to use an infinite horizon on which to base returns. However, optimizing returns over too short a time may limit rewards from seeing a much larger overall gain.\nMarkov Decision Problems What we’ve been talking about is called a Markov decision problem. Here’s how the problem is formalized.\nWe have:\n Set of states $S = {s1, \u0026hellip; , s_n}$ Set of actions $A = {a1, \u0026hellip; , a_n}$ Transition function $T[s, a, s_0]$ Reward function $R[s, a]$  What we’re trying to find is a policy $\\pi(s)$ that will maximize the reward. Unfortunately, we don’t know the $T$ or $R$, since that’s defined by the environment. So, the learner has to interact with the world and see what happens. Based on the reward, it can start generating policies.\nA way to encode this information is using experience tuples. Experience tuples are as follows: given a state $s_1$ and an action $a_1$ that we took, we were put into state $s'_1$ and got reward $r_1$. The tuple is shown like this:\n$\\langle s_1, a_1, s_1\u0026#39;, r_1 \\rangle$  Now, we can rename $s_1\u0026rsquo;$ to $s_2$, since that’s our new state, and then take a new action and see what happens, and we get a new tuple:\n$\\langle s_2, a_2, s_2\u0026#39;, r_2 \\rangle$  And we repeat this for many different combinations of states and actions, and then we’ll use the tuples to generate the policy. There are two ways to generate the policy:\n Model-based: For this method, we generate a model of $T[s, a, s_0]$ based on statistical analysis of the tuples. We look at a particular state and a particular action and see the probability of transitioning to another state. Same thing with $R[s, a]$. Then, we can use policy or value iteration to solve it. Model-free: This method keeps the data around and uses the original tuples to determine what the new state will be for a certain action. This is Q-learning.  Q-Learning Q-Learning is a model-free approach, which means that it doesn’t need to have any sort of model of the transition function $T$ or the reward function $R$. It builds a table of utility values as the agent interacts with the world. These are the Q values. At each state, the agent can then use the Q values to select the best action. Q-Learning is guaranteed to give an optimal policy, as it is proven to always converge.\n$Q$ represents the value of taking action $a$ in state $s$. This value includes the immediate reward for taking action $a$, and the discounted (future) reward for all optimal future actions after having taken $a$.\nHow do we use Q? What we want to find for a particular state is what policy, $\\prod(s)$ we should take. Using Q values, all we need to do is find the maximum $Q$ value for that state.\n$\\prod(s) = \\underset{a}{\\arg\\max}(Q[s,a])$  So, we go through each action a and see which action has the maximum $Q$ value for state $s$. Eventually, after learning enough, the agent will converge to the optimal policy, $\\pi^*(s)$, and optimal $Q$ table, $Q^*[s, a]$.\nHow do we get Q? To use the Q table, first we must generate it by learning. How do we go about that? Well it’s similar to previous learning algorithms, in that we provide it training data for which we know the outcomes. We then iterate over time and take actions based on the current policy (Q values), and generate experience tuples $\\langle s, a, s\u0026rsquo;, r \\rangle$ and generate the Q values based on the experience.\nIn a more detailed fashion:\n Initialize the Q table with small random values Compute $s$ Select $a$ Observe $r, s$ Update $Q$ Step forward in time, then repeat from step 2.  To update Q, we first need a formula to decide what it should be. What we can do is assign a learning rate, $\\alpha$, to weight the new observations. We can therefore update $Q$like this:\n$Q\u0026#39;[s, a] = Q[s, a] \u0026#43; \\alpha(\\textrm{improved estimate} - Q[s, a])$  As you can see, $Q$ converges as the improved estimate is the same as the current estimate (we’re at the best $Q$). Now, we need to know what the improved estimate is:\n$\\textrm{improved estimate} = \\textrm{immediate returns} \u0026#43; (\\textrm{discounted future rewards})$  Then, replacing discounted future rewards with the actual way of calculating it, and rearranging to only use the current value of $Q$ once, we find that the formula to calculate the new value of $Q$ for a state-action pair hs, ai, the formula is:\n$Q\u0026#39;[s, a] = (1 - \\alpha)Q[s, a] \u0026#43; \\alpha(r \u0026#43; \\gamma Q[s\u0026#39;, \\underset{a\u0026#39;}{\\arg\\max}(Q[s\u0026#39;, a\u0026#39;])])$  where:\n $r = R[s, a]$ is the immediate reward for taking an action $a$ in the state $s$ $\\gamma \\in [0, 1]$ is the discount factor to reduce the value of future rewards $s\u0026rsquo;$ is the resulting next state $\\underset{a\u0026rsquo;}{\\arg\\max}(Q[s\u0026rsquo;, a\u0026rsquo;])$ is the action which maximizes the Q-value among all possible actions $a\u0026rsquo;$ from $s\u0026rsquo;$, and $\\alpha \\in [0, 1]$ is the learning rate used to vary the weight given to new experiences compared to past Q-values. It’s typically around 0.2.  Exploration The success of a Q-learning algorithm depends on the exploration of the state-action space. If you only explore a small subset of it, you might not find the best policies. One way to ensure that you explore as much as possible is to introduce randomness into selecting actions during the learning phase. So basically, you see first whether you want to take the action with the maximal Q value or choose a random action, then if you take a random action, each action gets a probability which decreases over subsequent iterations.\nQ-Learning for Trading Now that we know what Q-learning is, we need to figure out how to apply it to the context of trading. That means that we need to define what state, action, and reward mean. Actions are straightforward, as there are basically three of them:\n Buy Sell Do Nothing  Our rewards can be daily returns or cumulative returns after a trade cycle (buy→sell). However, using daily returns will allow the agent to converge on a Q value more quickly, because if it waited until a sell, then it would have to look at all of the actions backwards until the buy to get that reward.\nNow, we just need to figure out how to determine state. Some good factors to determine state are:\n Adjusted Close/Simple Moving Average Bollinger Band value P/E ratio Holding stock (whether or not we’re holding the stock) Return since entry  Discretization Our state must be a single number so we can look it up in the table easily. To make it simpler, we’ll confine the state to be an integer, which means we need to discretize each factor and then combine them into an overall state. Our state space is discrete, so the combined value is the overall state. Say we have a state like this: The discretized state could be: 2950.\nTo discretize, what we do is take the data for a factor over its range, then divide it into n bins. Then we find the threshold by iterating over the data by the step size and taking the value at each position.\nstepsize = size(data) / n data.sort() for i in range(0, steps): threshold[i] = data[(i +1) * stepsize]  Problems with Q-Learning One main problem with Q-Learning is that it takes a lot of experience tuples to converge to the optimal Q value. This means the agent has to take many real interactions with the world (execute trades) to learn. The way this has been addressed is by using Dyna.\nDyna-Q Dyna is designed to improve the convergence of Q learning by building a model of $T$ and $R$ and then using Q learning to make decisions based on the model. However, the Q learning portion is still model-free, so it’s a mix of both.\nSo we do the Q-Learning steps, but after we take an action, we update the model of $T$ and $R$ with the new data, simulate a bunch of experiences based on the model, then update $Q$ based on these simulated experiences. To simulate the experiences, we basically generate random states and actions, and then find the new states/rewards based on the transition function and reward function.\nLearning T To figure out a model for $T$, what we can do is count the number of times that a transition to $s\u0026rsquo;$ by using the action $a$ in state $s$ occurred, then divide that by the total number of transitions to figure out the probability where $T_c$ is the number of times the transition occurred.\n$T[s, a, s\u0026#39;] = \\dfrac{T_c[s, a, s\u0026#39;]}{\\sum_{i} T_c[s, a, i]}$  Learning R To finalize the model, we need to find our expected reward, $R[s, a]$. Whenever we interact with the world, we get an immediate reward, $r$. We can use this to update our model for $R$ in a similar way to updating the $Q$ values where $\\alpha$ is again the learning rate:\n$R\u0026#39;[s, a] = (1 - \\alpha)R[s, a] \u0026#43; \\alpha r$  Conclusion So a summary of how Dyna-Q works is the following:\n MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\\\(','\\\\)']], displayMath: [['$$','$$'], ['\\[','\\]']], processEscapes: true, processEnvironments: true, skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'], TeX: { equationNumbers: { autoNumber: \"AMS\" }, extensions: [\"AMSmath.js\", \"AMSsymbols.js\"] } } });  MathJax.Hub.Queue(function() { // Fix  tags after MathJax finishes running. This is a // hack to overcome a shortcoming of Markdown. Discussion at // https://github.com/mojombo/jekyll/issues/199 var all = MathJax.Hub.getAllJax(), i; for(i = 0; i "
},
{
	"uri": "/6601/",
	"title": "6601",
	"tags": [],
	"description": "",
	"content": "TODO: coming soon\u0026hellip; PR\u0026rsquo;s welcome\n"
},
{
	"uri": "/7641/",
	"title": "7641",
	"tags": [],
	"description": "",
	"content": "TODO: coming soon\u0026hellip; PR\u0026rsquo;s welcome\n"
},
{
	"uri": "/6476/",
	"title": "6476",
	"tags": [],
	"description": "",
	"content": "TODO: coming soon\u0026hellip; PR\u0026rsquo;s welcome\n"
},
{
	"uri": "/6750/",
	"title": "6750",
	"tags": [],
	"description": "",
	"content": "TODO: coming soon\u0026hellip; PR\u0026rsquo;s welcome\n"
},
{
	"uri": "/6460/",
	"title": "6460",
	"tags": [],
	"description": "",
	"content": "TODO: coming soon\u0026hellip; PR\u0026rsquo;s welcome\n"
},
{
	"uri": "/",
	"title": "",
	"tags": [],
	"description": "",
	"content": " OMS:Notes About This project has two goals:\n Accelerate the rate of learning for all Provide resources to help those either 1) new to OMSCS or 2) new to a technical domain   If you want to go fast, go alone. If you want to go far, go together. \u0026ndash; AFRICAN PROVERB\n Contributing Contributions are very welcome. This is first and foremost a community effort by OMSCS for OMSCS.\n If you would like to make an occasional edit, please do so with the tab on the relevent page. If you would like to contribute more, please see the contributing guide \u0026ndash; coming soon  If any material here is out of date or can be improved, click on the \u0026ldquo;Improve this page\u0026rdquo; tab.\n "
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]